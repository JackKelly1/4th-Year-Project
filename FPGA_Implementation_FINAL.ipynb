{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fa0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "from qkeras import print_qstats\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense\n",
    "from qkeras import quantized_bits\n",
    "from qkeras import ternary\n",
    "from qkeras.estimate import print_qstats\n",
    "from qkeras.estimate import extract_model_operations\n",
    "from qkeras.utils import quantized_model_debug\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "from qkeras.utils import model_quantize\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import tempfile\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import zipfile\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9e8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 9 # arbitrary number\n",
    "np.random.seed(seed=seed)\n",
    "tf.random.set_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3e6d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jackkelly/Desktop/Submission\n"
     ]
    }
   ],
   "source": [
    "N_channels = 40\n",
    "data_path = os.getcwd()\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46517a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT, SHUFFLE AND SCALE DATA ###\n",
    "def processing_data(N_channels, file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # dataset\n",
    "    dataset = df.values\n",
    "    # input power and channels statuses\n",
    "    X = dataset[:,0:N_channels+1]\n",
    "    # channel SNRs\n",
    "    Y = dataset[:,N_channels+1:2*N_channels+1]\n",
    "    # shuffle necessary because while shuffle=True in .fit() shuffles the data, it splits into different datasets first\n",
    "    X, Y = shuffle(X, Y)\n",
    "    # scaling between 0 and 1\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    Y = min_max_scaler.fit_transform(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1385de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76fc2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{data_path}/Data/10000_initial_data.csv'\n",
    "X_scale, Y_scale = processing_data(N_channels, file_path)\n",
    "file_path = f'{data_path}/Data/10000_initial_data_testing.csv'\n",
    "X_test, Y_test = processing_data(N_channels, file_path)\n",
    "model = keras.models.load_model(f'{data_path}/Tuned_ANN_model.h5')\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "batch_size = 32\n",
    "epochs = 150\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a383cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97316b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_and_quantize(desired_sparsity, quantized_bit_number):\n",
    "    file_path = f'{data_path}/Data/10000_initial_data.csv'\n",
    "    X_scale, Y_scale = processing_data(N_channels, file_path)\n",
    "    file_path = f'{data_path}/Data/10000_initial_data_testing.csv'\n",
    "    X_test, Y_test = processing_data(N_channels, file_path)\n",
    "    model = keras.models.load_model(f'{data_path}/Tuned_ANN_model.h5')\n",
    "    print('---------------------------')\n",
    "    print(f'Desired sparsity: {desired_sparsity}, Quantized bit number: {quantized_bit_number}')\n",
    "    config = {\n",
    "      \"QDense\": {\n",
    "          \"kernel_quantizer\": f\"quantized_bits({quantized_bit_number},0,1)\",\n",
    "          \"bias_quantizer\": f\"quantized_bits({quantized_bit_number})\"\n",
    "      },\n",
    "      \"QActivation\": { \"relu\": f\"quantized_bits({quantized_bit_number})\" },\n",
    "    }\n",
    "    qmodel = model_quantize(model, config, 16, transfer_weights=True)\n",
    "    qmodel.summary()\n",
    "    pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=desired_sparsity, begin_step=0, end_step=-1, frequency=200)\n",
    "    }\n",
    "    pruned_q_model = prune_low_magnitude(qmodel, **pruning_params)\n",
    "    # 'prune_low_magnitude' requires a recompile.\n",
    "    pruned_q_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                        loss=keras.losses.MeanSquaredError(), metrics=['mean_squared_error'])\n",
    "    callbacks = [\n",
    "      tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    ]\n",
    "    pruned_q_model.fit(X_scale, Y_scale,\n",
    "                      batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks, verbose=0)\n",
    "    eval_pruned_model = pruned_q_model.evaluate(X_test, Y_test, verbose=0)[1]\n",
    "    print(f'Pruned model MSE: {eval_pruned_model}')\n",
    "    qmodel_stripped = tfmot.sparsity.keras.strip_pruning(pruned_q_model)\n",
    "    print_qstats(qmodel_stripped)\n",
    "    _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "    tf.keras.models.save_model(qmodel_stripped, pruned_keras_file, include_optimizer=False)\n",
    "    print('Saved pruned Keras model to:', pruned_keras_file)\n",
    "    # Size of model after pruning\n",
    "    size = get_gzipped_model_size(pruned_keras_file)\n",
    "    print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (size))\n",
    "    print('---------------------------')\n",
    "    return eval_pruned_model, size, qmodel_stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8093488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpqbhhfu6k.h5\n",
      "Size of gzipped baseline Keras model: 91005.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# baseline model size\n",
    "model = keras.models.load_model(f'{data_path}/Tuned_ANN_model.h5')\n",
    "_, baseline_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, baseline_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', baseline_keras_file)\n",
    "# Size of model after pruning\n",
    "baseline_size = get_gzipped_model_size(baseline_keras_file)\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (baseline_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7253b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Desired sparsity: 0.2, Quantized bit number: 4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/Final/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Pruned model MSE: 0.004524689633399248\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/Final/lib/python3.6/site-packages/qkeras/estimate.py:340: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_4_8)\n",
      "    dense_1                       : 14000 (smult_4_16)\n",
      "    dense_2                       : 4000  (smult_4_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_4_16                    : 18000\n",
      "    smult_4_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (4-bit unit)\n",
      "    dense_bias                     : 140   (4-bit unit)\n",
      "    dense_1_weights                : 14000 (4-bit unit)\n",
      "    dense_1_bias                   : 100   (4-bit unit)\n",
      "    dense_2_weights                : 4000  (4-bit unit)\n",
      "    dense_2_bias                   : 40    (4-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.3151\n",
      "    dense_1                        : 0.3194\n",
      "    dense_2                        : 0.2760\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.3111\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmp8jkqhm91.h5\n",
      "Size of gzipped baseline Keras model: 19782.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.4, Quantized bit number: 4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.004834233317524195\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_4_8)\n",
      "    dense_1                       : 14000 (smult_4_16)\n",
      "    dense_2                       : 4000  (smult_4_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_4_16                    : 18000\n",
      "    smult_4_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (4-bit unit)\n",
      "    dense_bias                     : 140   (4-bit unit)\n",
      "    dense_1_weights                : 14000 (4-bit unit)\n",
      "    dense_1_bias                   : 100   (4-bit unit)\n",
      "    dense_2_weights                : 4000  (4-bit unit)\n",
      "    dense_2_bias                   : 40    (4-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.4762\n",
      "    dense_1                        : 0.4721\n",
      "    dense_2                        : 0.4324\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.4664\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpuisfdj5s.h5\n",
      "Size of gzipped baseline Keras model: 18188.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.6, Quantized bit number: 4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.004646589979529381\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_4_8)\n",
      "    dense_1                       : 14000 (smult_4_16)\n",
      "    dense_2                       : 4000  (smult_4_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_4_16                    : 18000\n",
      "    smult_4_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (4-bit unit)\n",
      "    dense_bias                     : 140   (4-bit unit)\n",
      "    dense_1_weights                : 14000 (4-bit unit)\n",
      "    dense_1_bias                   : 100   (4-bit unit)\n",
      "    dense_2_weights                : 4000  (4-bit unit)\n",
      "    dense_2_bias                   : 40    (4-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.6636\n",
      "    dense_1                        : 0.6552\n",
      "    dense_2                        : 0.6161\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.6507\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpt1y0cl2a.h5\n",
      "Size of gzipped baseline Keras model: 15204.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.8, Quantized bit number: 4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.006530982907861471\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_4_8)\n",
      "    dense_1                       : 14000 (smult_4_16)\n",
      "    dense_2                       : 4000  (smult_4_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_4_16                    : 18000\n",
      "    smult_4_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (4-bit unit)\n",
      "    dense_bias                     : 140   (4-bit unit)\n",
      "    dense_1_weights                : 14000 (4-bit unit)\n",
      "    dense_1_bias                   : 100   (4-bit unit)\n",
      "    dense_2_weights                : 4000  (4-bit unit)\n",
      "    dense_2_bias                   : 40    (4-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.8575\n",
      "    dense_1                        : 0.8438\n",
      "    dense_2                        : 0.8114\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.8417\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmp5gxej758.h5\n",
      "Size of gzipped baseline Keras model: 9709.00 bytes\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Desired sparsity: 0.2, Quantized bit number: 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0010846592485904694\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_8_8)\n",
      "    dense_1                       : 14000 (smult_8_16)\n",
      "    dense_2                       : 4000  (smult_8_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_8_16                    : 18000\n",
      "    smult_8_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (8-bit unit)\n",
      "    dense_bias                     : 140   (8-bit unit)\n",
      "    dense_1_weights                : 14000 (8-bit unit)\n",
      "    dense_1_bias                   : 100   (8-bit unit)\n",
      "    dense_2_weights                : 4000  (8-bit unit)\n",
      "    dense_2_bias                   : 40    (8-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.2002\n",
      "    dense_1                        : 0.2026\n",
      "    dense_2                        : 0.2012\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.2018\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmp46e9s0q2.h5\n",
      "Size of gzipped baseline Keras model: 36276.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.4, Quantized bit number: 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0007890539127402008\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_8_8)\n",
      "    dense_1                       : 14000 (smult_8_16)\n",
      "    dense_2                       : 4000  (smult_8_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_8_16                    : 18000\n",
      "    smult_8_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (8-bit unit)\n",
      "    dense_bias                     : 140   (8-bit unit)\n",
      "    dense_1_weights                : 14000 (8-bit unit)\n",
      "    dense_1_bias                   : 100   (8-bit unit)\n",
      "    dense_2_weights                : 4000  (8-bit unit)\n",
      "    dense_2_bias                   : 40    (8-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.3949\n",
      "    dense_1                        : 0.4004\n",
      "    dense_2                        : 0.3970\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.3985\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpqkcl03om.h5\n",
      "Size of gzipped baseline Keras model: 31164.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.6, Quantized bit number: 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0004913024604320526\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_8_8)\n",
      "    dense_1                       : 14000 (smult_8_16)\n",
      "    dense_2                       : 4000  (smult_8_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_8_16                    : 18000\n",
      "    smult_8_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (8-bit unit)\n",
      "    dense_bias                     : 140   (8-bit unit)\n",
      "    dense_1_weights                : 14000 (8-bit unit)\n",
      "    dense_1_bias                   : 100   (8-bit unit)\n",
      "    dense_2_weights                : 4000  (8-bit unit)\n",
      "    dense_2_bias                   : 40    (8-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.5876\n",
      "    dense_1                        : 0.5972\n",
      "    dense_2                        : 0.5953\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.5945\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmp5xjuygo9.h5\n",
      "Size of gzipped baseline Keras model: 24190.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.8, Quantized bit number: 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0006868861382827163\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_8_8)\n",
      "    dense_1                       : 14000 (smult_8_16)\n",
      "    dense_2                       : 4000  (smult_8_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_8_16                    : 18000\n",
      "    smult_8_8                     : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (8-bit unit)\n",
      "    dense_bias                     : 140   (8-bit unit)\n",
      "    dense_1_weights                : 14000 (8-bit unit)\n",
      "    dense_1_bias                   : 100   (8-bit unit)\n",
      "    dense_2_weights                : 4000  (8-bit unit)\n",
      "    dense_2_bias                   : 40    (8-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.7855\n",
      "    dense_1                        : 0.7958\n",
      "    dense_2                        : 0.7923\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.7927\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmp1tpq1p4y.h5\n",
      "Size of gzipped baseline Keras model: 15004.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.2, Quantized bit number: 12\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model MSE: 0.0006227016565389931\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_12_8)\n",
      "    dense_1                       : 14000 (smult_12_16)\n",
      "    dense_2                       : 4000  (smult_12_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_12_16                   : 18000\n",
      "    smult_12_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (12-bit unit)\n",
      "    dense_bias                     : 140   (12-bit unit)\n",
      "    dense_1_weights                : 14000 (12-bit unit)\n",
      "    dense_1_bias                   : 100   (12-bit unit)\n",
      "    dense_2_weights                : 4000  (12-bit unit)\n",
      "    dense_2_bias                   : 40    (12-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.1956\n",
      "    dense_1                        : 0.1988\n",
      "    dense_2                        : 0.1983\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.1979\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpt48yzsmx.h5\n",
      "Size of gzipped baseline Keras model: 49627.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.4, Quantized bit number: 12\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0007671620114706457\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_12_8)\n",
      "    dense_1                       : 14000 (smult_12_16)\n",
      "    dense_2                       : 4000  (smult_12_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_12_16                   : 18000\n",
      "    smult_12_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (12-bit unit)\n",
      "    dense_bias                     : 140   (12-bit unit)\n",
      "    dense_1_weights                : 14000 (12-bit unit)\n",
      "    dense_1_bias                   : 100   (12-bit unit)\n",
      "    dense_2_weights                : 4000  (12-bit unit)\n",
      "    dense_2_bias                   : 40    (12-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.3905\n",
      "    dense_1                        : 0.3972\n",
      "    dense_2                        : 0.3960\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.3953\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpqmqqe1gj.h5\n",
      "Size of gzipped baseline Keras model: 41574.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.6, Quantized bit number: 12\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0011217029532417655\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_12_8)\n",
      "    dense_1                       : 14000 (smult_12_16)\n",
      "    dense_2                       : 4000  (smult_12_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_12_16                   : 18000\n",
      "    smult_12_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (12-bit unit)\n",
      "    dense_bias                     : 140   (12-bit unit)\n",
      "    dense_1_weights                : 14000 (12-bit unit)\n",
      "    dense_1_bias                   : 100   (12-bit unit)\n",
      "    dense_2_weights                : 4000  (12-bit unit)\n",
      "    dense_2_bias                   : 40    (12-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.5857\n",
      "    dense_1                        : 0.5958\n",
      "    dense_2                        : 0.5941\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.5930\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpa325ojp5.h5\n",
      "Size of gzipped baseline Keras model: 31506.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.8, Quantized bit number: 12\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0007813936681486666\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_12_8)\n",
      "    dense_1                       : 14000 (smult_12_16)\n",
      "    dense_2                       : 4000  (smult_12_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_12_16                   : 18000\n",
      "    smult_12_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (12-bit unit)\n",
      "    dense_bias                     : 140   (12-bit unit)\n",
      "    dense_1_weights                : 14000 (12-bit unit)\n",
      "    dense_1_bias                   : 100   (12-bit unit)\n",
      "    dense_2_weights                : 4000  (12-bit unit)\n",
      "    dense_2_bias                   : 40    (12-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.7811\n",
      "    dense_1                        : 0.7943\n",
      "    dense_2                        : 0.7921\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.7907\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpzvm8of9t.h5\n",
      "Size of gzipped baseline Keras model: 18911.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.2, Quantized bit number: 16\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0010344963520765305\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_16_8)\n",
      "    dense_1                       : 14000 (smult_16_16)\n",
      "    dense_2                       : 4000  (smult_16_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_16_16                   : 18000\n",
      "    smult_16_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (16-bit unit)\n",
      "    dense_bias                     : 140   (16-bit unit)\n",
      "    dense_1_weights                : 14000 (16-bit unit)\n",
      "    dense_1_bias                   : 100   (16-bit unit)\n",
      "    dense_2_weights                : 4000  (16-bit unit)\n",
      "    dense_2_bias                   : 40    (16-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.1952\n",
      "    dense_1                        : 0.1986\n",
      "    dense_2                        : 0.1983\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.1977\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmp3wrr3pks.h5\n",
      "Size of gzipped baseline Keras model: 61242.00 bytes\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Desired sparsity: 0.4, Quantized bit number: 16\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0008951331255957484\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_16_8)\n",
      "    dense_1                       : 14000 (smult_16_16)\n",
      "    dense_2                       : 4000  (smult_16_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_16_16                   : 18000\n",
      "    smult_16_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (16-bit unit)\n",
      "    dense_bias                     : 140   (16-bit unit)\n",
      "    dense_1_weights                : 14000 (16-bit unit)\n",
      "    dense_1_bias                   : 100   (16-bit unit)\n",
      "    dense_2_weights                : 4000  (16-bit unit)\n",
      "    dense_2_bias                   : 40    (16-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.3905\n",
      "    dense_1                        : 0.3972\n",
      "    dense_2                        : 0.3960\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.3953\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpb3nisiaw.h5\n",
      "Size of gzipped baseline Keras model: 50363.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.6, Quantized bit number: 16\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0005131296347826719\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_16_8)\n",
      "    dense_1                       : 14000 (smult_16_16)\n",
      "    dense_2                       : 4000  (smult_16_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_16_16                   : 18000\n",
      "    smult_16_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (16-bit unit)\n",
      "    dense_bias                     : 140   (16-bit unit)\n",
      "    dense_1_weights                : 14000 (16-bit unit)\n",
      "    dense_1_bias                   : 100   (16-bit unit)\n",
      "    dense_2_weights                : 4000  (16-bit unit)\n",
      "    dense_2_bias                   : 40    (16-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.5857\n",
      "    dense_1                        : 0.5957\n",
      "    dense_2                        : 0.5941\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.5930\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmpl8u0lcsf.h5\n",
      "Size of gzipped baseline Keras model: 37263.00 bytes\n",
      "---------------------------\n",
      "---------------------------\n",
      "Desired sparsity: 0.8, Quantized bit number: 16\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (QDense)               (None, 140)               5880      \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 40)                4040      \n",
      "=================================================================\n",
      "Total params: 24,020\n",
      "Trainable params: 24,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned model MSE: 0.0009417469264008105\n",
      "\n",
      "Number of operations in model:\n",
      "    dense                         : 5740  (smult_16_8)\n",
      "    dense_1                       : 14000 (smult_16_16)\n",
      "    dense_2                       : 4000  (smult_16_16)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_16_16                   : 18000\n",
      "    smult_16_8                    : 5740\n",
      "\n",
      "Weight profiling:\n",
      "    dense_weights                  : 5740  (16-bit unit)\n",
      "    dense_bias                     : 140   (16-bit unit)\n",
      "    dense_1_weights                : 14000 (16-bit unit)\n",
      "    dense_1_bias                   : 100   (16-bit unit)\n",
      "    dense_2_weights                : 4000  (16-bit unit)\n",
      "    dense_2_bias                   : 40    (16-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    dense                          : 0.7811\n",
      "    dense_1                        : 0.7943\n",
      "    dense_2                        : 0.7921\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.7907\n",
      "Saved pruned Keras model to: /var/folders/yp/nbwcv8453t3f3sx3xxwwycqm0000gn/T/tmp03p0x_rf.h5\n",
      "Size of gzipped baseline Keras model: 21793.00 bytes\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "size_results = []\n",
    "model_performance = []\n",
    "quantized_bit_numbers = [4, 8, 12, 16]\n",
    "sparsity_list = [0.2, 0.4, 0.6, 0.8]\n",
    "for i in quantized_bit_numbers:\n",
    "    for j in sparsity_list:\n",
    "        eval_pruned_model, size, qmodel_stripped = prune_and_quantize(j, i)\n",
    "        model_performance.append(eval_pruned_model)\n",
    "        size_results.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060873cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(size_results)\n",
    "print(model_performance[0:4])\n",
    "print(model_performance[4:8])\n",
    "print(model_performance[8:12])\n",
    "print(model_performance[12:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be9c43",
   "metadata": {},
   "source": [
    "# Model sizes (bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "plt.figure(figsize=(13,6))\n",
    "x = ['0.2','0.4','0.6','0.8']\n",
    "quantized_bit_numbers = [4, 8, 12, 16]\n",
    "\n",
    "values = np.array(size_results)\n",
    "idx = []\n",
    "for i in quantized_bit_numbers:\n",
    "    for sp in x:\n",
    "        idx.append(f'{sp} ({i})')\n",
    "    \n",
    "idx = np.array(idx)\n",
    "clrs = ['blue']*4 + ['green']*4 + ['red']*4 + ['black']*4\n",
    "plt.bar(idx, values, color=clrs, width=0.6)\n",
    "plt.ylabel('Size (bytes)')\n",
    "plt.xlabel('Sparsity (Quantized bits width)')\n",
    "# plt.axhline(y=baseline_size, linestyle='-.', linewidth=1, color='k')\n",
    "# plt.ylim([0,105000])\n",
    "\n",
    "colors = {'Quantized bit width = 4':'blue', 'Quantized bits width = 8':'green', 'Quantized bits width = 12':'red', 'Quantized bits width = 16':'black'}         \n",
    "labels = list(colors.keys())\n",
    "handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]\n",
    "plt.legend(handles, labels)\n",
    "\n",
    "plt.savefig(f'{data_path}/Figures/PQ/sizes.svg', bbox_inches='tight', format='svg', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff6ad6",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up baseline non-quantized model's performance\n",
    "baseline_model_performance = [model.evaluate(X_test, Y_test, verbose=1)[1]]*4\n",
    "q4 = model_performance[0:4]\n",
    "q8 = model_performance[4:8]\n",
    "q12 = model_performance[8:12]\n",
    "q16 = model_performance[12:16]\n",
    "plt.figure()\n",
    "plt.plot(sparsity_list, q4, 'x-', label='Quantized bits width = 4', color='blue')\n",
    "plt.plot(sparsity_list, q8, 'x-', label='Quantized bits width = 8', color='green')\n",
    "plt.plot(sparsity_list, q12, 'x-', label='Quantized bits width = 12', color='red')\n",
    "plt.plot(sparsity_list, q16, 'x-', label='Quantized bits width = 16', color='black')\n",
    "plt.plot(sparsity_list, baseline_model_performance, '-.', label='Baseline Model', color='orange')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Sparsity')\n",
    "plt.legend()\n",
    "plt.savefig(f'{data_path}/Figures/PQ/pruning_and_quantization_MSE_epochs.svg', bbox_inches='tight', format='svg', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cda4b8",
   "metadata": {},
   "source": [
    "# Bit operations (BOPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using formula\n",
    "def bop_calculator(n, m, bw, ba, fp):\n",
    "    num = m*n*((1-fp)*ba*bw + ba + bw + math.log(n, 2))\n",
    "    return num\n",
    "\n",
    "# where n (m) is the number of inputs (outputs),\n",
    "# bw (ba) is the bit width of the weights (activations),\n",
    "# and fp is the fraction of pruned layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_BOPs = 0\n",
    "# total_BOPs += bop_calculator(41, 41, 8, 8, 0.6)\n",
    "# total_BOPs += bop_calculator(41*140, 140, 8, 8, 0.6)\n",
    "# total_BOPs += bop_calculator(140*100, 100, 8, 8, 0.6)\n",
    "# total_BOPs += bop_calculator(100*40, 40, 8, 32, 0.6)\n",
    "# print(total_BOPs)\n",
    "\n",
    "# newtork: 41 -> 140 -> 100 -> 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_list = [0.2, 0.4, 0.6, 0.8]\n",
    "quantized_bit_numbers = [4, 8, 12, 16]\n",
    "bit_operations_comparison = []\n",
    "for q_width in quantized_bit_numbers:\n",
    "    for sparsity in sparsity_list:\n",
    "        total_BOPs = 0\n",
    "# #         is this definitely needed?\n",
    "#         total_BOPs += bop_calculator(41, 41, q_width, q_width, sparsity)\n",
    "        total_BOPs += bop_calculator(41*140, 140, q_width, q_width, sparsity)\n",
    "        total_BOPs += bop_calculator(140*100, 100, q_width, q_width, sparsity)\n",
    "        total_BOPs += bop_calculator(100*40, 40, q_width, 16, sparsity)\n",
    "        print(f'Quantized to {q_width} bits with a model sparsity of {sparsity}: {total_BOPs}')\n",
    "        bit_operations_comparison.append(total_BOPs)\n",
    "        \n",
    "# baseline model\n",
    "total_BOPs = 0\n",
    "# total_BOPs += bop_calculator(41, 41, 32, 32, 0)\n",
    "total_BOPs += bop_calculator(41*140, 140, 32, 32, 0)\n",
    "total_BOPs += bop_calculator(140*100, 100, 32, 32, 0)\n",
    "total_BOPs += bop_calculator(100*40, 40, 32, 32, 0)\n",
    "print(total_BOPs)\n",
    "for i in range(4):\n",
    "    bit_operations_comparison.append(total_BOPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ca053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting BOPs\n",
    "plt.figure()\n",
    "q4_bitop = bit_operations_comparison[0:4]\n",
    "q8_bitop = bit_operations_comparison[4:8]\n",
    "q12_bitop = bit_operations_comparison[8:12]\n",
    "q16_bitop = bit_operations_comparison[12:16]\n",
    "baseline_model_BOPs = bit_operations_comparison[16:20]\n",
    "plt.plot(sparsity_list, q4_bitop, 'x-', label='Quantized bits width = 4', color='blue')\n",
    "plt.plot(sparsity_list, q8_bitop, 'x-', label='Quantized bits width = 8', color='green')\n",
    "plt.plot(sparsity_list, q12_bitop, 'x-', label='Quantized bits width = 12', color='red')\n",
    "plt.plot(sparsity_list, q16_bitop, 'x-', label='Quantized bits width = 16', color='black')\n",
    "plt.plot(sparsity_list, baseline_model_BOPs, '-.', label='Baseline Model', color='orange')\n",
    "plt.ylabel('BOPs [10e9]')\n",
    "plt.xlabel('Sparsity')\n",
    "plt.legend()\n",
    "plt.savefig(f'{data_path}/Figures/PQ/BOPs.svg', bbox_inches='tight', format='svg', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(q4_bitop, q4, color='blue', label='Quantized bits width = 4')\n",
    "plt.scatter(q8_bitop, q8, color='green', label='Quantized bits width = 8')\n",
    "plt.scatter(q12_bitop, q12, color='red', label='Quantized bits width = 12')\n",
    "plt.scatter(q16_bitop, q16, color='black', label='Quantized bits width = 16')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('BOPs [10e8]')\n",
    "plt.legend()\n",
    "plt.savefig(f'{data_path}/Figures/PQ/BOPs_vs_Performance.svg', bbox_inches='tight', format='svg', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6060cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pruned_model, size, qmodel_stripped = prune_and_quantize(0.6, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5859b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_pruned_model)\n",
    "print(size)\n",
    "qmodel_stripped.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, values in holder.items():\n",
    "#     print(key)\n",
    "#     print(values['type'][2])\n",
    "#     print(values['number_of_operations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79298ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_qstats(qmodel)\n",
    "# signed multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4a99e",
   "metadata": {},
   "source": [
    "# CDF plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f4cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{data_path}/Data/10000_initial_data_testing.csv')\n",
    "# dataset\n",
    "dataset = df.values\n",
    "# input power and channels statuses\n",
    "X = dataset[:,0:N_channels+1]\n",
    "Y = dataset[:,N_channels+1:2*N_channels+1]\n",
    "\n",
    "xScaler = preprocessing.MinMaxScaler()\n",
    "yScaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "xScaler.fit(X)\n",
    "yScaler.fit(Y)\n",
    "\n",
    "xTrainNorm = xScaler.transform(X)\n",
    "yTrainNorm = yScaler.transform(Y)\n",
    "\n",
    "start_time = time.time()\n",
    "y_predicted = qmodel_stripped.predict(xTrainNorm)\n",
    "y_predicted_inverted = yScaler.inverse_transform(y_predicted)\n",
    "prediction_time = time.time() - start_time\n",
    "print(prediction_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b30850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDF_plot(x, y, e_type):\n",
    "    plt.figure()\n",
    "    mse_ecdf = plt.plot(x,y, marker='.', linestyle='none', color='blue')\n",
    "    plt.xlabel(f'{e_type} [dB]')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.savefig(f'{data_path}/Figures/PQ/CDF_plot_QP_{e_type}.svg', bbox_inches='tight', format='svg', dpi=1200)\n",
    "    plt.show()\n",
    "    \n",
    "mean_squared_error_store = []\n",
    "mean_absolute_error_store = []\n",
    "for i in range(10000):\n",
    "    mean_squared_error_store.append(mean_squared_error(y_predicted_inverted[i], Y[i]))\n",
    "    mean_absolute_error_store.append(mean_absolute_error(y_predicted_inverted[i], Y[i]))\n",
    "x_mse = np.sort(mean_squared_error_store)\n",
    "x_mae = np.sort(mean_absolute_error_store)\n",
    "y = np.arange(1, len(x_mse)+1)/len(x_mse)\n",
    "print('90th percentile mse = ', x_mse[9000],'dB')\n",
    "print('90th percentile mae = ', x_mae[9000],'dB')\n",
    "CDF_plot(x_mse, y, 'MSE')\n",
    "CDF_plot(x_mae, y, 'MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5492e5e",
   "metadata": {},
   "source": [
    "# Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(index):\n",
    "    y_actual = Y[index] * X[index][1:]\n",
    "    y_predicted = y_predicted_inverted[index] * X[index][1:]\n",
    "    \n",
    "    labels = [i for i in range(1,41)]\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18,5))\n",
    "    # plt.figure(figsize=(25,5))\n",
    "    rects1 = ax.bar(x - width/2, y_actual, width, label='Actual')\n",
    "    rects2 = ax.bar(x + width/2, y_predicted, width, label='Predicted')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('GSNR [dB]', fontsize=15)\n",
    "    ax.set_xlabel('Channel Number', fontsize=15)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.tick_params(axis='x', labelsize=15)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "    # ax.set_yticklabels(labels, fontsize=12)\n",
    "    ax.legend(fontsize=15, loc='upper right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{data_path}/Figures/PQ/pruned_quantized_model_bar_chart_{index}.svg', bbox_inches='tight', format='svg', dpi=1200)\n",
    "    plt.show()\n",
    "\n",
    "barplot(2500)\n",
    "barplot(5100)\n",
    "barplot(7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859e5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
